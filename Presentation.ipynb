{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is all about?\n",
    "### Once I came up with idea for simple Logistic Regression: what if we split one big model evaluated on all features into few smaller one evaluated only on some of the features.\n",
    "\n",
    "### Not only the theoretical evidence show that it will converge faster *but it indeed is*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The theoretical complexety of LogisticRegression is $O(k^2\\cdot(n + k))$, where $k$ is number of features and n - number of data points (though complexety maybe less in practice)\n",
    "##### If we divide data features into $m$ unique features subsets and fit $m$ models on them, the resulting complexety will be:\n",
    "$$\n",
    "m \\cdot O(\\frac{{k^2}}{{m^2}}\\cdot(n + \\frac{{k}}{{m}}))\n",
    "$$\n",
    "##### Which is approximately by m times less than fitting one model on the whole data.\n",
    "### But in reality this result depends on a data and hyperparameters (such as number of iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For demonstation I can run some experiments on toy datasets and demonstrate the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from AdditiveLogisticRegression import ALogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test on wine data (which is classification on only numerical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample data:\n",
      "0       14.02\n",
      "1        1.68\n",
      "2        2.21\n",
      "3       16.00\n",
      "4       96.00\n",
      "5        2.65\n",
      "6        2.33\n",
      "7        0.26\n",
      "8        1.98\n",
      "9        4.70\n",
      "10       1.04\n",
      "11       3.59\n",
      "12    1035.00\n",
      "Name: 29, dtype: float64\n",
      "Target(one of the following: (0, 1, 2)):\n",
      "0    0\n",
      "Name: 29, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "data = load_wine()\n",
    "target = pd.DataFrame(data.target)\n",
    "data = pd.DataFrame(data.data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3)\n",
    "random_sample = rd.randint(0, 100)\n",
    "print('Random sample data:', data.loc[random_sample], sep='\\n')\n",
    "print('Target(one of the following: (0, 1, 2)):', target.iloc[random_sample], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now let's run experiments to find expectation of accuracy and execution time ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of standard model: 0.9259259259259257 Accuracy of splitted model: 0.962962962962963\n",
      "Mean ration of execution time (standard / splitted): 1.4471698807695474\n"
     ]
    }
   ],
   "source": [
    "ratios = []\n",
    "accuracy_sub = []\n",
    "accuracy_full = []\n",
    "\n",
    "for i in range(100):\n",
    "    # Using my own LogisticRegression class which just rewrites the original\n",
    "    # You can set k (number of models for split) to a different value\n",
    "    # max_iter found to be the most controversial here, you can set it too\n",
    "    # and all the other parameters of simple LogisticRegression can be passed\n",
    "    additive_logistic = ALogisticRegression(k=4, max_iter=1000)  \n",
    "    additive_logistic.fit(X_train, y_train)\n",
    "\n",
    "    y_prediction = additive_logistic.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_prediction)\n",
    "    accuracy_sub.append(score)\n",
    "\n",
    "    # Built-in class attribute\n",
    "    sub_time = additive_logistic.time_evaluation\n",
    "\n",
    "    # Using the classic one on the whole dataset this time\n",
    "    model_check = LogisticRegression(max_iter=1000)\n",
    "    start = time.time()\n",
    "    model_check.fit(X_train, np.ravel(y_train))\n",
    "    end = time.time()\n",
    "\n",
    "    full_model_time = end - start\n",
    "    \n",
    "    y_preds = model_check.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_preds)\n",
    "    accuracy_full.append(score)\n",
    "\n",
    "    ratios.append(full_model_time/sub_time)\n",
    "\n",
    "print('Accuracy of standard model:', np.mean(accuracy_full), 'Accuracy of splitted model:', np.mean(accuracy_sub))\n",
    "print('Mean ration of execution time (standard / splitted):', np.mean(ratios))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
